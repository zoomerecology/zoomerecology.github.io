---
layout:     post
title:      Death Singularity
date:       2022-02-20 12:32:18
summary:    
tags:
 - iq
---

If science could somehow find a way to increase iq worldwide, would wars, crime and political differences dissipate?

If Frank Saulter's research and whatever would not indicate that, would they? I think that more problems would be solved specifically than conflictually. I suspect that frequency of warfare would probably be somewhat lower. But, and here's another frightening possibility, that if Iq were to increase considerably, the possibility of what's been sort of somewhat humorously referred to as the death singularity might increase. So you've heard of this idea of the singularity. So this is sort of moore's law extrapolated across all these different domains of technology, like, uh, nano technology and all this sort of thing.

Ray Kurzweil, back in, the sort of during the dotcom bubble era, was making all these prophecies about how those accelerating returns in and all patents sort of thing. He wrote a book called the singularity is near. Well, somebody came up with this idea that there might be a death singularity. So this is the idea that that, uh, weapons of mass destruction are increasing in terms of their efficiency to inflict casualty levels at the sort of mega death level. That's millions of deaths.

So at the turn of the 20th century, we had, the most destructive weapons we had might have been artillery cannons and zeppelins and mustard gas. Today we have hydrogen bombs with 50 megaton yields, which can inflict deaths in the multiple mega death level, you know, multiple 10 raised to the sixth power death level. Well, if you had people who were much smarter, and you raised Iq by, say, a standard deviation, and all of a sudden you had all these geniuses running around who could produce Kugle Blitz black holes using gamma ray lasers and things like that, or antimatter devices, or some other exotic weaponry, which we don't even know major, which we know nothing about and can't even imagine, um, because it requires new physics or something. We could have ended everything already through an accidental containment breach in a facility designed to weaponize black holes, or something like that. So this is the thing with it. It might be on the one hand that smarter people are going to be able to solve their problems more peacefully, but on the other hand, they're going to produce weapons that could end it all much more efficiently than anything we can produce today.